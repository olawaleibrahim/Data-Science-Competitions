{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FA2ysoWJEnP8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rsuS6j8JaokB"
   },
   "source": [
    "#Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "atlSSh7wJvUp",
    "outputId": "da649df5-571a-459a-bbae-ce42cd843dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.sh\n",
    "\n",
    "export CUD_HOME=/usr/local/cuda-10.1\n",
    "git clone https://github.com/NVIDIA/apex\n",
    "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9cRoAcHKLIT"
   },
   "outputs": [],
   "source": [
    "#For apex\n",
    "# !sh setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "kX-nG5z4ZEka",
    "outputId": "ea6d4731-a32f-49d8-d248-391965492f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 573kB 2.7MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.0MB 8.6MB/s \n",
      "\u001b[K     |████████████████████████████████| 890kB 16.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 3.7MB 25.6MB/s \n",
      "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zFP9Vvbfa6ww"
   },
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "juBoFMWpbiC_"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4sY0t1LMbY7q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UuQDTtadkdD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TPWKBEHyM6RG",
    "outputId": "f5f97295-c770-4118-eb75-9c1535b773f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8KHCLbBabvUb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8scAB3Ba9j5"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import (AutoTokenizer, AutoModel, AdamW, AutoConfig, get_linear_schedule_with_warmup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1X13z0e-ZZt"
   },
   "source": [
    "#Envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2I7sCm5J-atk"
   },
   "outputs": [],
   "source": [
    "seed = 2020 # for reproductibility\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iO4JywCqRwKM"
   },
   "outputs": [],
   "source": [
    "os.makedirs('MODELS/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUA0ZEK5eiHj"
   },
   "source": [
    "#Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTLKw0dQfRbK"
   },
   "outputs": [],
   "source": [
    "def process_prediction(preds):\n",
    "  r'''\n",
    "    This function helps us go from a classifiaction\n",
    "    problem to a regression one.\n",
    "    The regression values range are in [-1, 1].\n",
    "  '''\n",
    "\n",
    "  final_preds = []\n",
    "  for pred in preds:\n",
    "    argmax = np.argmax(pred, axis=0)\n",
    "    if argmax == 0: final_preds.append( -1*pred[0] )\n",
    "    elif argmax == 1: final_preds.append( 0 )\n",
    "    else: final_preds.append( pred[2] )\n",
    "    \n",
    "  return final_preds\n",
    "\n",
    "\n",
    "def rmse(true, pred):\n",
    "  return np.sqrt(mean_squared_error(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nji2bkWhkRqN"
   },
   "outputs": [],
   "source": [
    "def convert_examples(tweets, tokenizer, max_length): \n",
    "  bep = tokenizer.batch_encode_plus(tweets, add_special_tokens=True, max_length=max_length, \n",
    "                                    pad_to_max_length=True, return_token_type_ids=True,\n",
    "                                    return_attention_masks=True)\n",
    "  \n",
    "  return bep['input_ids'], bep['token_type_ids'], bep['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2U9bIQagD-rP"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "  def __init__(self, patience=3, mode='min'):\n",
    "    self.step = 0\n",
    "    self.patience = patience\n",
    "    self.mode = mode\n",
    "    self.stop = False\n",
    "    self.loss = np.inf\n",
    "\n",
    "  def update(self, loss):\n",
    "    if self.loss < loss:\n",
    "      self.step += 1\n",
    "    else: \n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "    \n",
    "    if self.step == self.patience: self.stop = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bshiJdrXU50q"
   },
   "outputs": [],
   "source": [
    "class VaccineOrNotModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(VaccineOrNotModel, self).__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name, config=config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(config.hidden_size, 3)\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        _, out = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        out = self.dropout(out)\n",
    "        logits = self.classifier(out)\n",
    "        logits = F.sigmoid(logits)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4j_oVpLtg3Zw"
   },
   "outputs": [],
   "source": [
    "class VaccineOrNotDataset(Dataset):\n",
    "  def __init__(self, input_ids, att_masks, token_ids, labels=None, task='train', classes=3):\n",
    "    self.input_ids = input_ids\n",
    "    self.att_masks = att_masks\n",
    "    self.token_ids = token_ids\n",
    "    self.labels = labels\n",
    "    self.c = classes\n",
    "    self.task = task\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "\n",
    "  def __getitem__(self, id):\n",
    "    out = {\n",
    "        'input_ids': torch.tensor(self.input_ids[id]),\n",
    "        'token_type_ids': torch.tensor(self.token_ids[id]),\n",
    "        'attention_mask': torch.tensor(self.att_masks[id]),\n",
    "    }\n",
    "\n",
    "    if self.task=='train': \n",
    "      out.update(\n",
    "        {\n",
    "          'label': torch.tensor(to_categorical(self.labels[id]+1, self.c), dtype=torch.float), #The former labels are in [-1, 1], so we add +1 to be in [0, 2]\n",
    "        }\n",
    "      )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFJBRysz1-nL"
   },
   "outputs": [],
   "source": [
    "def training_fn(model, opt, scheduler, criterion, train_ds, bs, device='cuda', n_labels=3):\n",
    "  train_dl = DataLoader(train_ds, bs)\n",
    "\n",
    "  avg_rmse = 0\n",
    "  avg_loss = 0\n",
    "\n",
    "  pbar = tqdm(train_dl, desc='Training ...')\n",
    "  model.train()\n",
    "\n",
    "  for i, data in enumerate(pbar):\n",
    "    input_ids = data['input_ids'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "    token_type_ids = data['token_type_ids'].to(device)\n",
    "    labels = data['label'].to(device)\n",
    "\n",
    "    opt.zero_grad()\n",
    "\n",
    "    logits = model(input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        token_type_ids=token_type_ids)\n",
    "        \n",
    "    loss = criterion(logits, labels)\n",
    "    custom_loss = rmse( labels.cpu().detach().numpy().argmax(1)-1, process_prediction(logits.cpu().detach().numpy()) )\n",
    "\n",
    "    avg_loss += loss.item()\n",
    "    avg_rmse += custom_loss\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    opt.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    pbar.set_postfix(loss=avg_loss/(i+1), rmse=avg_rmse/(i+1))\n",
    "    pbar.update()\n",
    "\n",
    "  return avg_rmse/len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zv8oNxIv1_iw"
   },
   "outputs": [],
   "source": [
    "def eval_fn(model, criterion, valid_ds, eval_bs, device='cuda', n_labels=3):\n",
    "  valid_dl = DataLoader(valid_ds, eval_bs)\n",
    "\n",
    "  avg_rmse = 0\n",
    "  avg_loss = 0\n",
    "\n",
    "  pbar = tqdm(valid_dl, desc='Evaluation ...')\n",
    "  model.eval()\n",
    "\n",
    "  for i, data in enumerate(pbar):\n",
    "    input_ids = data['input_ids'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "    token_type_ids = data['token_type_ids'].to(device)\n",
    "    labels = data['label'].to(device)\n",
    "\n",
    "    logits = model(input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        token_type_ids=token_type_ids\n",
    "        )\n",
    "    \n",
    "\n",
    "    loss = criterion(logits, labels)\n",
    "    \n",
    "    custom_loss = rmse( labels.cpu().detach().numpy().argmax(1)-1, process_prediction(logits.cpu().detach().numpy()) )\n",
    "\n",
    "    avg_loss += loss.item()\n",
    "    avg_rmse += custom_loss\n",
    "\n",
    "    pbar.set_postfix(loss=avg_loss/(i+1), rmse=avg_rmse/(i+1))\n",
    "    pbar.update()\n",
    "\n",
    "  return avg_rmse/len(valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZ2X7soJ_xxM"
   },
   "outputs": [],
   "source": [
    "def predict(input_ids, mask, token_ids, MODELS, bs=8, n_labels=3):\n",
    "    test_ds = VaccineOrNotDataset(input_ids, mask, token_ids, task='test')\n",
    "    testloader = DataLoader(test_ds, bs, shuffle=False)\n",
    "\n",
    "    predictions_proba = []\n",
    "\n",
    "    out = None\n",
    "\n",
    "    for data in tqdm(testloader):\n",
    "        x = data['input_ids'].to(device)\n",
    "\n",
    "        for i in range(n_folds):\n",
    "            if i == 0: out = MODELS[i](input_ids=x)\n",
    "            else: out += MODELS[i](input_ids=x)\n",
    "\n",
    "        out /= n_folds\n",
    "        out_probas = out.cpu().detach().numpy()\n",
    "\n",
    "        predictions_proba += out_probas.tolist()\n",
    "\n",
    "    return predictions_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_57a6pl6r3v"
   },
   "outputs": [],
   "source": [
    "def predict_by_fold(model, input_ids, mask, token_ids, bs=8, n_labels=3):\n",
    "    test_ds = VaccineOrNotDataset(input_ids, mask, token_ids, task='test')\n",
    "    testloader = DataLoader(test_ds, bs, shuffle=False)\n",
    "\n",
    "    predictions_proba = []\n",
    "\n",
    "    out = None\n",
    "\n",
    "    for data in tqdm(testloader):\n",
    "        x = data['input_ids'].to(device)\n",
    "        \n",
    "        out = model(input_ids=x)\n",
    "\n",
    "        out /= n_folds\n",
    "        out_probas = out.cpu().detach().numpy()\n",
    "\n",
    "        predictions_proba += out_probas.tolist()\n",
    "\n",
    "    return predictions_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-t1GZvHP3rT8"
   },
   "outputs": [],
   "source": [
    "def run_fold(fold, epochs, splits, bs, eval_bs, lr, model_name, path='MODELS/'):\n",
    "  tr, vr = splits\n",
    "  train_ds = VaccineOrNotDataset(np.take(tr_ids, tr, axis=0), np.take(tr_masks,tr, axis=0),\n",
    "                                np.take(tr_tokens,tr, axis=0), np.take(train_labels,tr, axis=0)) \n",
    "  valid_ds = VaccineOrNotDataset(np.take(tr_ids, vr, axis=0), np.take(tr_masks,vr, axis=0),\n",
    "                                np.take(tr_tokens,vr, axis=0), np.take(train_labels,vr, axis=0)) \n",
    "\n",
    "  train_dl = DataLoader(train_ds, bs)\n",
    "  valid_dl = DataLoader(valid_ds, eval_bs)\n",
    "\n",
    "  device='cuda'\n",
    "\n",
    "  model = VaccineOrNotModel(model_name)\n",
    "  model.to(device)\n",
    "\n",
    "  num_train_steps = int(len(train_ds) / bs*epochs)\n",
    "\n",
    "  param_optimizer = list(model.named_parameters())\n",
    "  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "  optimizer_parameters = [\n",
    "      {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "      {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "  ]\n",
    "\n",
    "  opt = AdamW(optimizer_parameters, lr=lr)\n",
    "  scheduler = get_linear_schedule_with_warmup(\n",
    "            opt, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    "        )\n",
    "\n",
    "  criterion = nn.BCELoss()\n",
    "  es = EarlyStopping(patience=3)\n",
    "\n",
    "  best_rmse = np.inf\n",
    "\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "    training_fn(model, opt, scheduler, criterion, train_ds, bs, device)\n",
    "    score = eval_fn(model, criterion, valid_ds, eval_bs, device)\n",
    "    es.update(score)\n",
    "\n",
    "    if score < best_rmse:\n",
    "      best_rmse = score\n",
    "      torch.save(model.state_dict(), f'{path}model_state_dict_{fold}.bin')\n",
    "\n",
    "    if es.stop:\n",
    "      print(\"Early Stopping triggered\")\n",
    "      return best_rmse\n",
    "      \n",
    "  return best_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yhJHW1q3dX82"
   },
   "source": [
    "#Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RZcXsKZddEK"
   },
   "outputs": [],
   "source": [
    "path = 'drive/My Drive/Zindi/#ZindiWeekendz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AspysT1ca8_Y"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(path+'Train.csv')\n",
    "test = pd.read_csv(path+'Test.csv')\n",
    "sample = pd.read_csv(path+'SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQ3eS5h4gtYr"
   },
   "source": [
    "#Cleaning and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhNbxGVxi64H"
   },
   "outputs": [],
   "source": [
    "model_name = 'roberta-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RofU7BuFgv7k"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OryYhzsnG1To"
   },
   "outputs": [],
   "source": [
    "train['safe_text'] = train['safe_text'].apply(str)\n",
    "test['safe_text'] = test['safe_text'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4jGq8_mUHy_w"
   },
   "outputs": [],
   "source": [
    "train['safe_text'] = train['safe_text'].apply(str.lower)\n",
    "test['safe_text'] = test['safe_text'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i8YNkYQUG9i2"
   },
   "outputs": [],
   "source": [
    "train['safe_text'] = train['safe_text'].apply(lambda x: x.replace('&amp;', ' '))\n",
    "test['safe_text'] = test['safe_text'].apply(lambda x: x.replace('&amp;', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i3UuAZm0CYf_"
   },
   "outputs": [],
   "source": [
    "train['safe_text'] = train['safe_text'].apply(lambda x: x.replace('<user>', ' '))\n",
    "test['safe_text'] = test['safe_text'].apply(lambda x: x.replace('<user>', ' '))\n",
    "\n",
    "train['safe_text'] = train['safe_text'].apply(lambda x: x.replace('<url>', ' '))\n",
    "test['safe_text'] = test['safe_text'].apply(lambda x: x.replace('<url>', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TngQMlh6bJw-"
   },
   "outputs": [],
   "source": [
    "train['safe_text'] = train['safe_text'].apply(lambda x: x.replace('#', ' '))\n",
    "test['safe_text'] = test['safe_text'].apply(lambda x: x.replace('#', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pr7QJhNDHaP6"
   },
   "outputs": [],
   "source": [
    "train['safe_text'] = train['safe_text'].apply(lambda x: x.strip('.').strip())\n",
    "test['safe_text'] = test['safe_text'].apply(lambda x: x.strip('.').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xtttcYRZqv9"
   },
   "outputs": [],
   "source": [
    "train.drop(index=[4798, 4799], inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "jbIIbyFpCuja",
    "outputId": "d5f5cad7-8899-4a9b-f397-776948e79b4f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>safe_text</th>\n",
       "      <th>label</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CL1KWCMY</td>\n",
       "      <td>me   the big homie meanboy3000  meanboy  mb  m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E3303EME</td>\n",
       "      <td>i'm 100% thinking of devoting my career to pro...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M4IVFSMS</td>\n",
       "      <td>whatcausesautism vaccines, do not vaccinate yo...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1DR6ROZ4</td>\n",
       "      <td>i mean if they immunize my kid with something ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J77ENIIE</td>\n",
       "      <td>thanks to   catch me performing at la nuit nyc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  ... agreement\n",
       "0  CL1KWCMY  ...       1.0\n",
       "1  E3303EME  ...       1.0\n",
       "2  M4IVFSMS  ...       1.0\n",
       "3  1DR6ROZ4  ...       1.0\n",
       "4  J77ENIIE  ...       1.0\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "prk5WGKagwrI"
   },
   "outputs": [],
   "source": [
    "train_text = train['safe_text'].values\n",
    "train_labels = train['label'].values\n",
    "\n",
    "test_text = test['safe_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIroAINVsVFF"
   },
   "outputs": [],
   "source": [
    "tr_ids, tr_tokens, tr_masks = convert_examples(train_text, tokenizer, max_length=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPH-m6iYs_EV"
   },
   "outputs": [],
   "source": [
    "te_ids, te_tokens, te_masks = convert_examples(test_text, tokenizer, max_length=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gzmc4dFFgxHb"
   },
   "source": [
    "#Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1a7ho5I_4zKe"
   },
   "outputs": [],
   "source": [
    "#These Hyperparameters could be tune\n",
    "epochs = 10\n",
    "n_folds = 10\n",
    "bs = 32\n",
    "eval_bs = 4\n",
    "lr = 3e-5\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHBUICfJ3LUo"
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_folds, shuffle=True, random_state=seed)\n",
    "all_folds = list(skf.split(tr_ids, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mb47-o44x78j"
   },
   "outputs": [],
   "source": [
    "cv_score = 0\n",
    "for fold in range(n_folds):\n",
    "  splits = all_folds[fold]\n",
    "\n",
    "  s = run_fold(fold, epochs, splits, bs, eval_bs, lr, model_name=model_name)\n",
    "  cv_score += s/n_folds\n",
    "print(\"Avg rmse : \", cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilrM4KAw-t4Q"
   },
   "source": [
    "#Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "keqCNlnG0hJM"
   },
   "outputs": [],
   "source": [
    "#Just to cool down the memory :)\n",
    "del train,tokenizer,tr_ids,tr_masks,tr_tokens\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWji_OY4-w8M"
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for fold in range(n_folds):\n",
    "  model = VaccineOrNotModel(model_name)\n",
    "  model.to(device)\n",
    "  model.load_state_dict(torch.load(f'MODELS/model_state_dict_{fold}.bin'))\n",
    "  model.eval()\n",
    "\n",
    "  preds.append( predict_on_fold(model, te_ids, te_masks, te_tokens, bs=8) )\n",
    "\n",
    "  del model\n",
    "  gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lshLLtah_n5V"
   },
   "outputs": [],
   "source": [
    "predictions_proba = np.sum(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oacey_BD_n2J"
   },
   "outputs": [],
   "source": [
    "predictions = process_prediction(predictions_proba) #Final step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MDkKnf6CLVG"
   },
   "source": [
    "#Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "4b8C2DRw_nzC",
    "outputId": "919143d3-86f6-48d3-d458-0595d2acc066"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00BHHHP1</td>\n",
       "      <td>-0.518568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00UNMD0E</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01AXPTJF</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01HOEQJW</td>\n",
       "      <td>0.921080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01JUKMAO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID    target\n",
       "0  00BHHHP1 -0.518568\n",
       "1  00UNMD0E  0.000000\n",
       "2  01AXPTJF  0.000000\n",
       "3  01HOEQJW  0.921080\n",
       "4  01JUKMAO  0.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = test[['tweet_id']]\n",
    "subs['target'] = predictions\n",
    "subs.columns = ['ID', 'target']\n",
    "subs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "aRoFH8R3_nwR",
    "outputId": "fc20e2a0-ad2b-49a0-ac3a-b8032f584595"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.305531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.480103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.886795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.841104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.935912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target\n",
       "count  5177.000000\n",
       "mean      0.305531\n",
       "std       0.480103\n",
       "min      -0.886795\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.841104\n",
       "max       0.935912"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gm_zHVYf_nm2"
   },
   "outputs": [],
   "source": [
    "subs.to_csv(f'arch_{model_name}_folds_{n_folds}_epochs_{epochs}_bs_{bs}_lr_{lr}_cv_{cv_score}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubFnZn3BsaMr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "rsuS6j8JaokB",
    "w1X13z0e-ZZt",
    "yhJHW1q3dX82",
    "YQ3eS5h4gtYr"
   ],
   "machine_shape": "hm",
   "name": "ToVaccineOrNotVaccine.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
